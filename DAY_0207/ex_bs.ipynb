{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup 첫 예제 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"head-title\" id=\"hot-articles-head-title\">\n",
      "      \n",
      "      \n",
      "      중고거래 인기매물\n",
      "  </h1>\n",
      "중고거래 인기매물\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('https://www.daangn.com/hot_articles')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "print(bs.h1)\n",
    "print(bs.h1.string.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그를 사용하여 요소에 직접 접근하기\n",
    "    - title의 태그에 접근 (soup.태그명)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 샘플 HTML 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_example ='''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>BeautifulSoup 활용</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 id=\"heading\">Heading 1</h1>\n",
    "    <p>Paragraph</p>\n",
    "    <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
    "    <div id=\"link\">\n",
    "        <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
    "\n",
    "        <div id=\"class1\">\n",
    "            <p id=\"first\">class1's first paragraph</p>\n",
    "            <a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
    "\n",
    "            <p id=\"second\">class1's second paragraph</p>\n",
    "            <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
    "            <p id=\"third\">class1's third paragraph</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"text_id2\">\n",
    "        Example page\n",
    "        <p>g</p>\n",
    "    </div>\n",
    "    <h1 id=\"footer\">Footer</h1>\n",
    "</body>\n",
    "</html>'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그를 사용하여 요소에 직접 접근하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>BeautifulSoup 활용</title>\n",
      "BeautifulSoup 활용\n",
      "BeautifulSoup 활용\n"
     ]
    }
   ],
   "source": [
    "# <title> 태그에 접근(soup.태그명)\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "\n",
    "print(soup.title)  # <title> 태그 전체를 가져옴\n",
    "print(soup.title.string)  # <title>태그의 텍스트만 리턴\n",
    "print(soup.title.get_text())  # .stirng, .txet(예전 버전)와 동일한 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그명.parent : 해당 태그를 포함하고 있는 부모 (<head> 태그 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<title>BeautifulSoup 활용</title>\n",
       "</head>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그를 사용하여 요소에 직접 접근하기\n",
    "    - body 태그에 접근\n",
    "    - h1태그 접근\n",
    "    - a태그 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1 id=\"heading\">Heading 1</h1>\n",
       "<p>Paragraph</p>\n",
       "<span class=\"red\">BeautifulSoup Library Examples!</span>\n",
       "<div id=\"link\">\n",
       "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
       "<div id=\"class1\">\n",
       "<p id=\"first\">class1's first paragraph</p>\n",
       "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
       "<p id=\"second\">class1's second paragraph</p>\n",
       "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
       "<p id=\"third\">class1's third paragraph</p>\n",
       "</div>\n",
       "</div>\n",
       "<div id=\"text_id2\">\n",
       "        Example page\n",
       "        <p>g</p>\n",
       "</div>\n",
       "<h1 id=\"footer\">Footer</h1>\n",
       "</body>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "Heading 1\n"
     ]
    }
   ],
   "source": [
    "print(soup.h1)\n",
    "print(soup.h1.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "google\n",
      "www.google.com\n",
      "www.google.com\n"
     ]
    }
   ],
   "source": [
    "print(soup.a)\n",
    "print(soup.a.string)  # <a> 태그 배부의 텍스트 추출(google)\n",
    "print(soup.a['href'])  # <a> 태그 내부의 href 속성의 url 추출\n",
    "print(soup.a.get('href'))  # a['href']와 동일한 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기초 : find() 메서드 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"link\">\n",
       "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
       "<div id=\"class1\">\n",
       "<p id=\"first\">class1's first paragraph</p>\n",
       "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
       "<p id=\"second\">class1's second paragraph</p>\n",
       "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
       "<p id=\"third\">class1's third paragraph</p>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수 사용\n",
    "    - 여러 div 태그 중 특정 속성을 가지는 항목 추출\n",
    "        - 딕셔너리 형태로 입력 (id속성의 값이 'text_id2'인 항목 검색)\n",
    "    - .string, .text(deprecated) 또는 get_text()\n",
    "        - 추출된 요소에서 텍스트만 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"text_id2\">\n",
       "        Example page\n",
       "        <p>g</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', {'id' : 'text_id2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        Example page\\n        g\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_text = soup.find('div', {'id' : 'text_id2'})\n",
    "div_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_text.string  # None 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수 활용\n",
    "    - a 태그 및 a 태그의 href 속성 추출\n",
    "    - a 태그 중 class 속성값이 'internal_link'인 정보 추출  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "/pages/page1.html\n",
      "/pages/page1.html\n",
      "Page1\n"
     ]
    }
   ],
   "source": [
    "href_link = soup.find('a', {'class' : 'internal_link'})  # 딕셔너리 형태\n",
    "href_link = soup.find('a', class_ = 'internal_link')  # class_사용 : class는 파이썬 예약어\n",
    "\n",
    "print(href_link)  #\t<a class=\"internal_link\",...>\n",
    "print(href_link['href'])  #\t<a> 태그 내부 href 속성의 값(url)을 추출\n",
    "print(href_link.get('href'))  #\t['href']와 동일 기능\n",
    "print(href_link.text)  # <a> Page1 </a>태그 내부의 텍스트(Page1) 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수 활용\n",
    "    - a 태그 내부의 모든 속성 가져오기 : attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href_link.attrs:\t {'class': ['internal_link'], 'href': '/pages/page1.html'}\n",
      "class 속성값:  ['internal_link']\n",
      "values(): dict_values([['internal_link'], '/pages/page1.html'])\n",
      "values[0]: ['internal_link'], values[1]: /pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "print('href_link.attrs:\t', href_link.attrs)\t # <a>태그 내부의 모든 속성 출력\n",
    "print('class 속성값: ', href_link['class'])  # class 속성의 value 출력\n",
    "print('values():', href_link.attrs.values())  # 모든 속성들의 값 출력\n",
    "values = list(href_link.attrs.values())\t # dictionary 값들을 리스트로 변경\n",
    "print('values[0]: {0}, values[1]: {1}'.format(values[0], values[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수 활용\n",
    "    - href 속성의 값이 'www.google.com'인 항목 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href_value:  <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "www.google.com\n",
      "google\n"
     ]
    }
   ],
   "source": [
    "href_value = soup(attrs = {'href' : 'www.google.com'})\n",
    "href_value = soup.find('a', attrs = {'href' : 'www.google.com'})\n",
    "\n",
    "print('href_value: ', href_value)\n",
    "print(href_value['href'])\n",
    "print(href_value.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수\n",
    "    - span 태그의 속성 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span\ttag: <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "attrs: {'class': ['red']}\n",
      "value: ['red']\n",
      "text: BeautifulSoup Library Examples!\n"
     ]
    }
   ],
   "source": [
    "span_tag = soup.find('span')\n",
    "\n",
    "print('span\ttag:', span_tag)\n",
    "print('attrs:',\tspan_tag.attrs)\n",
    "print('value:',\tspan_tag.attrs['class'])\n",
    "print('text:',\tspan_tag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find() 함수 활용\n",
    "    - class 속성\n",
    "        - class 속성은 여러 개의 값을 가질 수 있음 (multi_valued attribute)\n",
    "        - 따라서 list 형태로 리턴함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['passed', 'a', 'b', 'c'], 'id': 'row1 example'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "tr = '''\n",
    "<table>\n",
    "    <tr class=\"passed a b c\" id=\"row1 example\"><td>t1</td></tr>\n",
    "    <tr class=\"failed\" id=\"row2><td>t2</td></tr>\n",
    "</table>\n",
    "'''\n",
    "table = BeautifulSoup(tr, 'html.parser')\n",
    "for row in table.find_all('tr'):  # find_all('tag') : 해당 tag를 모두 찾아서 리스트로 리턴\n",
    "    print(row.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_all()\n",
    "    - 모든 div 태그 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div_tags length :  3\n",
      "-----------------------------------------------\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "-----------------------------------------------\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "-----------------------------------------------\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "\n",
    "# 모든 div 태그를 검색 (리스트 형태로 반환)\n",
    "div_tags = soup.find_all('div')\n",
    "print('div_tags length : ', len(div_tags))\n",
    "\n",
    "for div in div_tags:\n",
    "    print('-----------------------------------------------')\n",
    "    print(div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_all()\n",
    "    - 모든 a 태그 검색 및 속성 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "url:www.google.com. text : google\n",
      "\n",
      "<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>\n",
      "url:www.naver.com. text : naver\n",
      "\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "url:/pages/page1.html. text : Page1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "\n",
    "for alink in links:\n",
    "    print(alink)\n",
    "    print(f\"url:{alink['href']}. text : {alink.string}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_all() 함수\n",
    "    - 특정 태그 중 여러 속성값을 한 번에 검색\n",
    "        - 검색할 속성값을 리스트 형태로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"external_link\" href=\"www.google.com\">google</a>,\n",
       " <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러 <a> 태그에서 2개의 class 속성값 검색 : 'external_link', 'internal_link'만 검색\n",
    "link_tags = soup.find_all('a', {'class' : ['external_link', 'internal_link']})\n",
    "link_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<p id=\"third\">class1's third paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "# <p> 태그의 id값이 'first', 'third'인 항목 검색\n",
    "p_tags = soup.find_all('p', {'id' : ['first', 'third']})\n",
    "for p in p_tags:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기초 : select() 함수 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select_one() 함수\n",
    "    - 첫 번째 일치하는 태그만 리턴 : find()와 동일 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n",
      "head.text: BeautifulSoup 활용\n"
     ]
    }
   ],
   "source": [
    "# <head> 태그 검색\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "head = soup.select_one('head')\n",
    "print(head)\n",
    "print('head.text:', head.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 id=\"heading\">Heading 1</h1>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 <h1>태그 검색\n",
    "h1 = soup.select_one('h1')\n",
    "h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select_one() 함수 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 id=\"footer\">Footer</h1>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <h1>태그의 id 검색 : #id\n",
    "footer = soup.select_one('h1#footer')\n",
    "footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 이름 검색 : 태그.클래스이름\n",
    "class_link = soup.select_one('a.internal_link')\n",
    "class_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page1\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "print(class_link.string)\n",
    "print(class_link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select_one() 함수 예제\n",
    "    - 계층적 하위 태그 접근 #1\n",
    "        - (상위태그 > 하위태그) 형식으로 접근 : 태그가 단계적으로 존재할 때\n",
    "        - find() 함수와 비교\n",
    "    - 계층적 하위 태그 접근 #2 : 공백으로 하위 태그 선언\n",
    "        - (상위태그 하위태그) 형식으로 접근 : 자손 관계의 하위태그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"external_link\" href=\"www.google.com\">google</a>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link1 = soup.select_one('div#link > a.external_link')\n",
    "link1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find external_link:  <a class=\"external_link\" href=\"www.google.com\">google</a>\n"
     ]
    }
   ],
   "source": [
    "# 하위 태그를 찾을 때, 반복적으로 코드를 작성\n",
    "link_find = soup.find('div', {'id' : 'link'})\n",
    "\n",
    "external_link = link_find.find('a', {'class' : 'external_link'})\n",
    "print('find external_link: ', external_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"second\">class1's second paragraph</p>\n",
      "class1's second paragraph\n"
     ]
    }
   ],
   "source": [
    "link2 = soup.select_one('div#class1 p#second')\n",
    "print(link2)\n",
    "print(link2.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1_all:  [<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n"
     ]
    }
   ],
   "source": [
    "# 모든 <h1> 태그 검색\n",
    "h1_all = soup.select('h1')\n",
    "print('h1_all: ', h1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com\n",
      "www.naver.com\n",
      "/pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "# 모든 url 링크 검색\n",
    "url_links = soup.select('a')\n",
    "for link in url_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "www.naver.com\n"
     ]
    }
   ],
   "source": [
    "# <div id=\"class1\"> 내부의 모든 url 검색\n",
    "div_urls = soup.select('div#class1 > a')\n",
    "print(div_urls)\n",
    "print(div_urls[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"exteranl_link\" href=\"www.naver.com\">naver</a>,\n",
       " <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <div id=\"class1\"> 내부의 모든 <a>태그는 자손 관계\n",
    "# - 공백으로 구분할 수 있음\n",
    "div_urls2 = soup.select('div#class1 a')\n",
    "div_urls2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select() 함수\n",
    "    - 여러 항목 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <h1>태그의 id가 \"heading\"과 \"footer\"를 모두 검색\n",
    "# -쉼표(,)로 나열함\n",
    "\n",
    "h1 = soup.select('#heading, #footer')\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"external_link\" href=\"www.google.com\">google</a>,\n",
       " <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <a>태그의 class이름이 \"external_link\"와 \"internal_link\" 모두 검색\n",
    "url_links = soup.select('a.external_link, a.internal_link')\n",
    "url_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_anthem = '''<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>애국가</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p id=\"title\">애국가</p>\n",
    "        <p class=\"content\">\n",
    "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>                \n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'애국가'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제목과 가사 내용 추출\n",
    "soup = BeautifulSoup(national_anthem, 'html.parser')\n",
    "soup.select_one('p#title').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contents = soup.select('p.content')\n",
    "for content in contents:\n",
    "    print(content.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
